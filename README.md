# Toxic-comment-classification-problem-using-bert-in-keras

In the world full of internet everybody has liberty to write and give their opinion at any social medial platform. people usually choose to write their opinion on website"s comment section and thread section but many times it has observed that rather than giving constructive advise people use this opportunity to bully or abuse others and start fighting with each other in the threads and comment section where they sometimes even give threat and insult each other .To specifically identify and restrict these type of comments internet companies are working very hardly and this competition was also held on similar topic.

TO solve this problem 3 experiments have been done In which different models was used.
The first model was Random forest classifier which gives a Local AUC score On Validation data as 0.93 And at the leaderboard at private section it gave 0.95
There was two bert model used and the final prediction was the mean of both the different bert model.


## The final Score surpassed the first place score on the leader board.

### 1st rank( public score) :: 0.98856
### My sore (public score)  :: 0.98993

### Refer to blog for detailed understanding:
https://yagvendra-singh-52.medium.com/toxic-comment-classification-using-bert-keras-and-huggingface-surpassing-first-place-score-d9df922ea95d

## Note :: please Use Google Colab to see the notebook there are plots generated using Plotly and the output of graphs can not be seen in github Just "click" open in                colab on the top of ipython notebook             
